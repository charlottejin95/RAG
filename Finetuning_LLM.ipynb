{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlottejin95/RAG/blob/main/Finetuning_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning LLM"
      ],
      "metadata": {
        "id": "VtzEPcHEl2Xa"
      },
      "id": "VtzEPcHEl2Xa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "AlKo9xZ5mHe3"
      },
      "id": "AlKo9xZ5mHe3"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch jsonlines pandas datasets transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ng9OC2nmmKzg",
        "outputId": "1c6c1ecf-2549-4f2a-bfc3-5fd7b0729540"
      },
      "id": "ng9OC2nmmKzg",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQb1CU-tFj-b",
        "outputId": "a86016aa-f5ce-40ab-f065-0de2178390e2",
        "collapsed": true
      },
      "id": "EQb1CU-tFj-b",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import textwrap\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "VU4pP_R6mv1B"
      },
      "id": "VU4pP_R6mv1B",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "753b9c5b",
      "metadata": {
        "id": "753b9c5b"
      },
      "source": [
        "## Function of Finetuning: finetuned vs. non-finetuned models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86d2cd9",
      "metadata": {
        "id": "c86d2cd9"
      },
      "source": [
        "### Non-Finetuned model--Meta AI's LLaMA LLM\n",
        "\n",
        "**Web link**: https://huggingface.co/openlm-research/open_llama_3b_v2\n",
        "\n",
        "**Introduction**: In the above repo link, the team presents a **permissively licensed open source reproduction of Meta AI's LLaMA large language model**. They are releasing a series of **3B, 7B and 13B models trained on 1T tokens**. They also provide PyTorch and JAX weights of pre-trained OpenLLaMA models, as well as evaluation results and comparison against the original LLaMA models. The v2 model is better than the old v1 model trained on a different data mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load LLM"
      ],
      "metadata": {
        "id": "EnIgyefItwSJ"
      },
      "id": "EnIgyefItwSJ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1ef82350",
      "metadata": {
        "id": "1ef82350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273c3bf2-d001-4fc4-d2fb-35eeb8b57f3a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"openlm-research/open_llama_3b_v2\"\n",
        "\n",
        "#Load the tokenizer associated with the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#AutoTokenizer automatically figure out the right tokenizer class for the model (LlamaTokenizer in this case)\n",
        "\n",
        "#Loads the pretrained model for causal language modeling(predict the next word based on prev context)\n",
        "non_finetuned = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "#AutoModelForCausalLM automatically loads the correct architecture for language modeling (LlamaForCausalLM in this case)\n",
        "#device_map=\"auto\"--lets the library automatically place model layers on available hardware\n",
        "\n",
        "#Specify which device to use if necessary\n",
        "# non_finetuned.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q&A Example"
      ],
      "metadata": {
        "id": "wVEpmPXXt9Nk"
      },
      "id": "wVEpmPXXt9Nk"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "213b3936",
      "metadata": {
        "id": "213b3936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e59c8c4-57ea-40af-dce1-27d163e62704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "Tell me how to train my dog to sit \n",
            "\n",
            "Output Answer:\n",
            "Tell me how to train my dog to sit and stay. I have a 10 month old puppy. I have been working with\n",
            "him on sit and stay. I have been working with him for about 2 weeks. I have been using a clicker and\n",
            "treats. I have been using a treat to get him to sit and then I click and give him a treat. I have\n",
            "been using a treat to get him to stay. I have been using a treat to get him to\n"
          ]
        }
      ],
      "source": [
        "#Q&A example using non-finetuned model\n",
        "input_text = \"Tell me how to train my dog to sit\"\n",
        "non_finetuned_output = non_finetuned.generate(tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device),\n",
        "                                              max_length=100)\n",
        "#tokenizer()--Converts the text into token IDs that the model can understand; return_tensors=\"pt\"--return PyTorch tensors\n",
        "#.input_ids.to()--Moves the input_ids tensor to the appropriate device defined before\n",
        "#.generate()--The model generates based on input, up to max_length tokens, including the input\n",
        "\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(textwrap.fill(tokenizer.decode(non_finetuned_output[0], #convert result back to readable text\n",
        "                                     skip_special_tokens=True), #ignore special tokens like <s>, </s>, <pad> in the output\n",
        "                    width=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Inference Function"
      ],
      "metadata": {
        "id": "86VH9yx2uAy-"
      },
      "id": "86VH9yx2uAy-"
    },
    {
      "cell_type": "code",
      "source": [
        "#Self-defined function to generate reuseable Q&A using LLM\n",
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(text,\n",
        "                               return_tensors=\"pt\",\n",
        "                               truncation=True,\n",
        "                               max_length=max_input_tokens\n",
        "                               ) #Encodes text into token IDs, as a PyTorch tensor.\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(input_ids=input_ids.to(device),\n",
        "                                                max_length=max_output_tokens\n",
        "                                                )#Generates tokens with the model.The result includes both prompt & new tokens.\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt,\n",
        "                                                      skip_special_tokens=True\n",
        "                                                      )#Converts generated tokens into readable text.\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "cxJXr86LCJ8q"
      },
      "id": "cxJXr86LCJ8q",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9fd34a82",
      "metadata": {
        "id": "9fd34a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ead47ee-53c0-4cb1-9a8e-ca8bb49297cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "What do you think of Mars? \n",
            "\n",
            "Output Answer:\n",
            "\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great place to live.\n",
            "I think it's a great\n"
          ]
        }
      ],
      "source": [
        "# Q&A Example 2:\n",
        "input_text = \"What do you think of Mars?\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(inference(input_text, non_finetuned, tokenizer))\n",
        "#print(textwrap.fill(inference(input_text, non_finetuned, tokenizer),width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b22652ae",
      "metadata": {
        "id": "b22652ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b87936a-1b6f-4ee7-d69f-d7dab1b55414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "taylor swift's best friend \n",
            "\n",
            "Output Answer:\n",
            "\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift's best friend\n",
            "taylor swift\n"
          ]
        }
      ],
      "source": [
        "# Q&A Example 3:\n",
        "input_text = \"taylor swift's best friend\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(inference(input_text, non_finetuned, tokenizer))\n",
        "#print(textwrap.fill(inference(input_text, non_finetuned, tokenizer),width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "05d6d640",
      "metadata": {
        "id": "05d6d640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2209db70-d881-454d-d3a8-272a0e54bf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "Agent: I'm here to help you with your Amazon deliver order.\n",
            "Customer: I didn't get my item\n",
            "Agent: I'm sorry to hear that. Which item was it?\n",
            "Customer: the blanket\n",
            "Agent: \n",
            "\n",
            "Output Answer:\n",
            " I'm sorry to hear that. Which item was it?\n",
            "Customer: the blanket\n",
            "Agent: I'm sorry to hear that. Which item was it?\n",
            "Customer: the blanket\n",
            "Agent: I'm sorry to hear that.\n"
          ]
        }
      ],
      "source": [
        "# Q&A Example 4:\n",
        "input_text = \"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(inference(input_text, non_finetuned, tokenizer))\n",
        "#print(textwrap.fill(inference(input_text, non_finetuned, tokenizer),width=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**:\n",
        "\n",
        "Based on the previous examples, we can notice that there are multiple problems with unfinetuned model:\n",
        "- Lacks task-specific skills\n",
        "- Generate many repetition loops\n",
        "- Cannot follow instructions well\n",
        "\n",
        "Because an unfinetuned model has only been trained on general web-scale text using causal language modeling. While it has learned a lot of basic language patterns, it has not been specialized for specific tasks like Q&A, summarization, or following user instructions."
      ],
      "metadata": {
        "id": "0hV4ckFlwXrU"
      },
      "id": "0hV4ckFlwXrU"
    },
    {
      "cell_type": "code",
      "source": [
        "del non_finetuned\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "AZ-gMNXBJXF8"
      },
      "id": "AZ-gMNXBJXF8",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetuned model--Llama Mediocredev text generation\n",
        "\n",
        "**Web link**: https://huggingface.co/mediocredev/open-llama-3b-v2-chat\n",
        "\n",
        "**Introduction**: The Mediocredev open Llama 3b V2 Chat Gguf model is a powerful tool for text generation, designed to provide efficient and accurate results. Built on the LLaMA 3B v2 architecture, it has been quantized to reduce its size while maintaining its capabilities.It can process and respond to text-based inputs quickly, making it suitable for a wide range of applications, from chatbots to content generation."
      ],
      "metadata": {
        "id": "431uNphPxO4h"
      },
      "id": "431uNphPxO4h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load LLM"
      ],
      "metadata": {
        "id": "rULJZhP22zv4"
      },
      "id": "rULJZhP22zv4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809c1d28",
      "metadata": {
        "id": "809c1d28"
      },
      "outputs": [],
      "source": [
        "model_name = \"mediocredev/open-llama-3b-v2-chat\"\n",
        "\n",
        "#Load the tokenizer associated with the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#Loads the finetuned model for text-generation modeling\n",
        "finetuned_model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q&A Example--with vs. without prompt format"
      ],
      "metadata": {
        "id": "eM_I72X823Rb"
      },
      "id": "eM_I72X823Rb"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "588ad61c",
      "metadata": {
        "id": "588ad61c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5dfe99-5a82-4e47-d66f-e2e11389445b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "Tell me how to train my dog to sit \n",
            "\n",
            "Output Answer:\n",
            ".\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit.\n",
            "How to train a dog to sit\n"
          ]
        }
      ],
      "source": [
        "#Input without special instruction\n",
        "input_text = \"Tell me how to train my dog to sit\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "finetuned_output = inference(input_text, finetuned_model, tokenizer)\n",
        "print(finetuned_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7e8f0e7f",
      "metadata": {
        "id": "7e8f0e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b694e073-9a1c-4ad2-87b2-b9d1b4926a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "[INST]Tell me how to train my dog to sit[/INST] \n",
            "\n",
            "Output Answer:\n",
            " I don't have a dog, but here are some general steps to train your dog to sit:\n",
            "\n",
            "1. Start by sitting down in a comfortable position with your dog.\n",
            "\n",
            "2. Hold a treat in your hand and place it in front of your dog's nose.\n",
            "\n",
            "3. Slowly move the treat up to your dog's nose and say \"sit\" as you\n"
          ]
        }
      ],
      "source": [
        "#Input in instruction-tuned prompt format (common with models like LLaMA, OpenLLaMA instruction models)\n",
        "#[INST] ... [/INST](Many chat-optimized models are trained with these tags, and if see them, will respond more intelligently)\n",
        "input_text = \"[INST]Tell me how to train my dog to sit[/INST]\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "finetuned_output = inference(input_text, finetuned_model, tokenizer)\n",
        "print(finetuned_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "01cf87f6",
      "metadata": {
        "id": "01cf87f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5d93a5-c280-42cb-c6ca-6e533721a29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "[INST]What do you think of Mars?[/INST] \n",
            "\n",
            "Output Answer:\n",
            " I do not have the ability to think or have opinions. However, I can provide information about mars.\n",
            "Mars is the fourth-largest planet in our solar system and the second-smallest planet in terms of\n",
            "diameter. It is known for its red color due to iron oxide deposits on its surface. Mars is also the\n",
            "only planet in our solar system that has a thin atmosphere, which is composed mainly of carbon\n",
            "dioxide.\n"
          ]
        }
      ],
      "source": [
        "#Example 2:\n",
        "input_text = \"[INST]What do you think of Mars?[/INST]\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(textwrap.fill(inference(input_text, finetuned_model, tokenizer),width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "32db06c7",
      "metadata": {
        "id": "32db06c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b133d61-da2e-4b96-adc1-5a328c4a7d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "[INST]taylor swift's best friend[/INST] \n",
            "\n",
            "Output Answer:\n",
            " I do not have a personal opinion or feelings. However, I can provide information about taylor\n",
            "swift's best friend.   taylor swift's best friend is john mayer. They have been friends since they\n",
            "were teenagers and have been inseparable ever since. They have collaborated on several songs\n",
            "together, including \"love story\" and \"dear john.\" they also attend the same concerts and have been\n"
          ]
        }
      ],
      "source": [
        "#Example 3:\n",
        "input_text = \"[INST]taylor swift's best friend[/INST]\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(textwrap.fill(inference(input_text, finetuned_model, tokenizer),width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "be48bda1",
      "metadata": {
        "id": "be48bda1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e99df4-fb60-42a4-ac7f-8ef68feedeb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "Agent: I'm here to help you with your Amazon deliver order.\n",
            "Customer: I didn't get my item\n",
            "Agent: I'm sorry to hear that. Which item was it?\n",
            "Customer: the blanket\n",
            "Agent: \n",
            "\n",
            "Output Answer:\n",
            " I see. Can you please provide me with your order number?\n",
            "Customer: 1234567890123456\n",
            "Agent: Thank you. I see that your blanket was shipped to your address.\n"
          ]
        }
      ],
      "source": [
        "#Example 4: Without prompt format\n",
        "input_text = \"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(inference(input_text, finetuned_model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example 4: With prompt format: [INST]...[/INST], ???(answer format more like agent & customer conversation)\n",
        "input_text = \"\"\"[INST]Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:???[/INST]\"\"\"\n",
        "print('Input Question:')\n",
        "print(input_text,'\\n')\n",
        "print('Output Answer:')\n",
        "print(inference(input_text, finetuned_model, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrLPI7vWa3ri",
        "outputId": "6a968fc0-c620-47a6-ac7d-aee1fdf0fa26"
      },
      "id": "JrLPI7vWa3ri",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Question:\n",
            "[INST]Agent: I'm here to help you with your Amazon deliver order.\n",
            "Customer: I didn't get my item\n",
            "Agent: I'm sorry to hear that. Which item was it?\n",
            "Customer: the blanket\n",
            "Agent:???[/INST] \n",
            "\n",
            "Output Answer:\n",
            " Agent: I'm sorry to hear that. Can you please provide me with your order number and the tracking number? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del finetuned_model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "q54geZuHM4yd"
      },
      "id": "q54geZuHM4yd",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9f512b13",
      "metadata": {
        "id": "9f512b13"
      },
      "source": [
        "## Model Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "vSFIRr659uGH"
      },
      "id": "vSFIRr659uGH"
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines #Change each data point to one row\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from pprint import pprint # print output\n",
        "\n",
        "import datasets #Load dataset using DT_names\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "k2fu42Zo9yi7"
      },
      "id": "k2fu42Zo9yi7",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b944c304",
      "metadata": {
        "id": "b944c304"
      },
      "source": [
        "### Data for model finetuning vs pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd7700c",
      "metadata": {
        "id": "3cd7700c"
      },
      "source": [
        "#### Pretraining data set\n",
        "\n",
        "**Web Link**: https://huggingface.co/datasets/allenai/c4/blob/main/README.md\n",
        "\n",
        "**Introduction**: A colossal, cleaned version of Common Crawl's web crawl corpus (Based on [Common Crawl dataset]( https://commoncrawl.org)). This is the processed version of Google's C4 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load data"
      ],
      "metadata": {
        "id": "ayFMLT1JExKX"
      },
      "id": "ayFMLT1JExKX"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bc92a955",
      "metadata": {
        "id": "bc92a955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9cbd7db245fc4fe896e8a81cd9638c13",
            "998492119061482697d20f3aeff317f3",
            "c32aae2521a94a658ccfd163de0a5391",
            "756f52f7bb03416caff90f65393d37c5",
            "4cb1e5938729476d9c6a12028f25a0e0",
            "456f291b801d411d8d7db229bed08df3",
            "9128703570074f46a692fc0d834c8040",
            "8c0f5075e144485da51a48455d3688ce",
            "072eb8782c654a78a50e4ab0f8cda068",
            "f66cdcfa731b425c8a024b153c1e7de4",
            "1433e99ad46f420ca32d3d8d47cc10fe",
            "df6557d18a8b46708ecb221691022ad4",
            "67664747bdf44590b8f3041f3932ffa2",
            "e4015752550844a9a8ab57489edc2c1c",
            "e147af5adabc4641938d173ffc3d3762",
            "861a25ee5b82446ca2badb8fbce6f132",
            "f807060b9ad546f187eeaf1e0d27f6b2",
            "5e859a59eb3a4b1c9583ca70653b64e7",
            "4e86a9d76e3b49df8daf27a96785a15b",
            "58f293ea2cff4d16a7965bd74b4a85dc",
            "211ce442a7bf4b59978ba2602654f706",
            "396f222d13bf4109ba139ec76b5c5b86",
            "3a53c7c57bd540f78332ad87ac57b03e",
            "e0600c7e4a2944fd968b0672e9c48263",
            "0a5a82233e434c7c97569edd70028764",
            "af2fc0d2ec284b10a3aae81d5807156f",
            "3e9998d92e8148a284b386d73637cc20",
            "54a3062071e94572954c7251087a53d9",
            "3cbcaa16023445c69323a349fd9dcacf",
            "bf610d964e634377b39807437ae1b1de",
            "9430dea62a284130a415ceba2f5c6456",
            "8095cfb4b1564016a18fe2329fccf039",
            "b3180a63ccc14c419a3bff8320581b7b"
          ]
        },
        "outputId": "d99fda32-da8d-4d05-aa1f-96fce97039b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbd7db245fc4fe896e8a81cd9638c13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df6557d18a8b46708ecb221691022ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a53c7c57bd540f78332ad87ac57b03e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Load pretraining data as a streaming iterable dataset\n",
        "pretrained_dataset = load_dataset(\"allenai/c4\", \"en\",\n",
        "                                  split=\"train\",\n",
        "                                  streaming=True #Instead of downloading entire dataset to disk, enables lazy loading--Samples are streamed one by one\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Examples"
      ],
      "metadata": {
        "id": "4M87qxZzEzPP"
      },
      "id": "4M87qxZzEzPP"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5ae5f773",
      "metadata": {
        "id": "5ae5f773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b9744b-3b21-44a1-fff0-1245ecf41ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained dataset:\n",
            "Data Example  1 :\n",
            "Text:\n",
            " Beginners BBQ Class Taking Place in Missoula! Do you want to get better at making delicious BBQ? You\n",
            "will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class\n",
            "BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for\n",
            "everyone who wants to get better with their culinary skills. He will teach you everything you need\n",
            "to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat\n",
            "selection and trimming, plus smoker and fire information. The cost to be in the class is $35 per\n",
            "person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and\n",
            "you will be tasting samples of each meat that is prepared.\n",
            "\n",
            "timestamp:  2019-04-25 12:57:54\n",
            "url:  https://klyq.com/beginners-bbq-class-taking-place-in-missoula/ \n",
            "\n",
            "Data Example  2 :\n",
            "Text:\n",
            " Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012. I've got a 500gb internal\n",
            "drive and a 240gb SSD. When trying to restore using disk utility i'm given the error \"Not enough\n",
            "space on disk ____ to restore\" But I shouldn't have to do that!!! Any ideas or workarounds before\n",
            "resorting to the above? Use Carbon Copy Cloner to copy one drive to the other. I've done this\n",
            "several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One\n",
            "step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition\n",
            "scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the\n",
            "clone, the resulting drive won't be bootable. CCC usually works in \"file mode\" and it can easily\n",
            "copy a larger drive (that's mostly empty) onto a smaller drive. If you tell CCC to clone a drive you\n",
            "did NOT boot from, it can work in block copy mode where the destination drive must be the same size\n",
            "or larger than the drive you are cloning from (if I recall). I've actually done this somehow on Disk\n",
            "Utility several times (booting from a different drive (or even the dvd) so not running disk utility\n",
            "from the drive your cloning) and had it work just fine from larger to smaller bootable clone.\n",
            "Definitely format the drive cloning to first, as bootable Apple etc.. Thanks for pointing this out.\n",
            "My only experience using DU to go larger to smaller was when I was trying to make a Lion install\n",
            "stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that\n",
            "wouldn't fit is there was slightly more than 4 GB of data.\n",
            "\n",
            "timestamp:  2019-04-21 10:07:13\n",
            "url:  https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Show the pretraining data\n",
        "n = 2\n",
        "print(\"Pretrained dataset:\")\n",
        "\n",
        "#itertools.islice()--grab the first n items from the streaming iterable\n",
        "top_n = itertools.islice(pretrained_dataset, n)\n",
        "num=1\n",
        "for i in top_n:\n",
        "  print('Data Example ',num,':')\n",
        "  print('Text:\\n', textwrap.fill(i['text'],width=100))\n",
        "  print('\\ntimestamp: ',i['timestamp'])\n",
        "  print('url: ',i['url'],'\\n')\n",
        "  num+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc33338d",
      "metadata": {
        "id": "cc33338d"
      },
      "source": [
        "#### Finetuning dataset\n",
        "\n",
        "Using this dataset in this project for finetuning\n",
        "\n",
        "**Web Link**: https://huggingface.co/datasets/lamini/lamini_docs\n",
        "\n",
        "**Introduction**: [Lamini](https://huggingface.co/lamini) is an LLM engine that allows any developer to train high-performing LLMs on large datasets using the Lamini library. It uses Lamini dataset generator pipeline to generate a filtered dataset having around 37k questions and responses samples."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load Data"
      ],
      "metadata": {
        "id": "b88NGxxKE2RJ"
      },
      "id": "b88NGxxKE2RJ"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "66668b38",
      "metadata": {
        "id": "66668b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "4e543fabe46e47afb736ae2522b98f93",
            "829adf5eabf2414abd501e37e79f57cd",
            "b4154afba8574bf0848f8f2861e765df",
            "e523f1712e9b48d7aaa37d2f211da0f8",
            "8dd1109ac4314494aace28a5d404b2cb",
            "e1b99abed6494eeca700a42085fd5ee3",
            "e5b7bbf84b8540e4bb883d0021bc2201",
            "a6053b3613af41dcb09026e831a95fab",
            "e8d3dff0dd764402b41adc0b5426f065",
            "20855815f6944934848f7e58ac666c05",
            "015176cffc8f400e89efff21f6c80336",
            "dfd5070bc8fe4afea59ee2f1b9db2d00",
            "3c1472b024d74d4195180ca2cf59bb16",
            "c33f0a252b134d88baffbf20ef92c83a",
            "d881cec28d3447159e4afb0cf01cb714",
            "4e771e4f69b14415822184eab453976f",
            "d2c15d1b123244db8c2db4cf9af24367",
            "f6b3073e81614c6791b31f6e5037d444",
            "79d4f838061643709f90e2420a1bf8c3",
            "6ef3d0c8da3f4eb7a0b13470d50139d4",
            "d34eabcaa4dd4a83855d8c8b9858de2f",
            "10bc9cc7253d4f5ea863fad6c7cc6689",
            "9ee8665a6d5f432fbf7885e29094c5ab",
            "aaa740601bcb4613a53aedb4f09252e0",
            "ba7aa6770263421090379af215ec7809",
            "d7f0c7df37134e70908f9f94eef979e9",
            "3b458cf64943456c9c79b7a311cb4942",
            "5c309d4686e8439fa38277d2d71901f2",
            "7fb5d1c03ba042f79194994693a0e1bc",
            "0790fb3ca918464196dc223bbd394764",
            "4ce2bc648b714809978ccebe5c89f364",
            "ff130575dbc14975b1b2601c24982e77",
            "9c5d39bf0e214cceb2791dcf1510a32c",
            "2c9164d035374f8c8a8c9e32f3aba3f2",
            "08b094cb59df4458a53e88630e721430",
            "d1eaa8b7c5984576b7569f7602d868f8",
            "0911a79504bc4c7ca055c3c31948e1d7",
            "ea5621833c8b4c0da8b2a452dc8d1aeb",
            "5111ea32fb494bd0ba5749aeab563017",
            "0d0596b354824541ba5c56dd9ef5dc95",
            "7f1bebd9f14943bab744a0038d7a4e93",
            "04634dbb4d104b449326211f5a5b3986",
            "b085e0a4f0b04c23a2d2d56f0742aa2c",
            "cd468c5960e5401e8acabbe2a06fcd38",
            "09e99d68b6034c46a6dcf20066a3adde",
            "b359f3de18634cc5ac99a4188ce6e2c3",
            "11267b13b17c4243b40b376c163a38f7",
            "b0946875479a463ea3a9848a0fff2f9e",
            "542246a5d523423cb9f51f099649a8b6",
            "dab0b2f5e2b84fc597e34ec7d3351448",
            "7721ba052c14443aa5b98e31b106018a",
            "b2333b9e7baa4f27aa770f129a4397ce",
            "6cfbfe8f75544c0ba3afab3dab67d37c",
            "ffc299360736440dadd3644d98085a7a",
            "beb058663ed64b488188480b442a36d9"
          ]
        },
        "outputId": "5abd19d7-95fb-4903-d87b-8fddf82e8977"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/577 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e543fabe46e47afb736ae2522b98f93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-5cdebbc48da41394.parquet:   0%|          | 0.00/615k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfd5070bc8fe4afea59ee2f1b9db2d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-4c77a066a883f339.parquet:   0%|          | 0.00/83.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee8665a6d5f432fbf7885e29094c5ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1260 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c9164d035374f8c8a8c9e32f3aba3f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/140 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09e99d68b6034c46a6dcf20066a3adde"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the dataset from Hugging Face\n",
        "dataset = load_dataset('lamini/lamini_docs')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the dataset info\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDtCKriUCRvq",
        "outputId": "e2da4db5-3080-42f1-b638-f2958ed2be9f"
      },
      "id": "aDtCKriUCRvq",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 140\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Examples"
      ],
      "metadata": {
        "id": "TVeDH_9iE4gd"
      },
      "id": "TVeDH_9iE4gd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the 'train' split\n",
        "train_dataset = dataset['train']\n",
        "\n",
        "# Data Examples\n",
        "for i in range(2):  # Adjust the range as needed\n",
        "    print('Data Example ',i+1,':')\n",
        "    print('Question:\\n', textwrap.fill(train_dataset[i]['question'],width=100))\n",
        "    print('\\nAnswer:\\n', textwrap.fill(train_dataset[i]['answer'],width=100))\n",
        "    print('\\ninput_ids: ',train_dataset[i]['input_ids'])\n",
        "    print('attention_mask: ',train_dataset[i]['attention_mask'])\n",
        "    print('labels: ',train_dataset[i]['labels'],'\\n')\n"
      ],
      "metadata": {
        "id": "JOyAQ2gdPR1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239548f5-d3dd-4294-87e0-fa47ea9a501e"
      },
      "id": "JOyAQ2gdPR1x",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Example  1 :\n",
            "Question:\n",
            " How can I evaluate the performance and quality of the generated text from Lamini models?\n",
            "\n",
            "Answer:\n",
            " There are several metrics that can be used to evaluate the performance and quality of generated text\n",
            "from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how\n",
            "well the model predicts the next word in a sequence, while BLEU score measures the similarity\n",
            "between the generated text and a reference text. Human evaluation involves having human judges rate\n",
            "the quality of the generated text based on factors such as coherence, fluency, and relevance. It is\n",
            "recommended to use a combination of these metrics for a comprehensive evaluation of the model's\n",
            "performance.\n",
            "\n",
            "input_ids:  [2347, 476, 309, 7472, 253, 3045, 285, 3290, 273, 253, 4561, 2505, 432, 418, 4988, 74, 3210, 32, 2512, 403, 2067, 17082, 326, 476, 320, 908, 281, 7472, 253, 3045, 285, 3290, 273, 4561, 2505, 432, 418, 4988, 74, 3210, 13, 1690, 44229, 414, 13, 378, 1843, 54, 4868, 13, 285, 1966, 7103, 15, 3545, 12813, 414, 5593, 849, 973, 253, 1566, 26295, 253, 1735, 3159, 275, 247, 3425, 13, 1223, 378, 1843, 54, 4868, 5593, 253, 14259, 875, 253, 4561, 2505, 285, 247, 3806, 2505, 15, 8801, 7103, 8687, 1907, 1966, 16006, 2281, 253, 3290, 273, 253, 4561, 2505, 1754, 327, 2616, 824, 347, 25253, 13, 2938, 1371, 13, 285, 17200, 15, 733, 310, 8521, 281, 897, 247, 5019, 273, 841, 17082, 323, 247, 11088, 7103, 273, 253, 1566, 434, 3045, 15]\n",
            "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "labels:  [2347, 476, 309, 7472, 253, 3045, 285, 3290, 273, 253, 4561, 2505, 432, 418, 4988, 74, 3210, 32, 2512, 403, 2067, 17082, 326, 476, 320, 908, 281, 7472, 253, 3045, 285, 3290, 273, 4561, 2505, 432, 418, 4988, 74, 3210, 13, 1690, 44229, 414, 13, 378, 1843, 54, 4868, 13, 285, 1966, 7103, 15, 3545, 12813, 414, 5593, 849, 973, 253, 1566, 26295, 253, 1735, 3159, 275, 247, 3425, 13, 1223, 378, 1843, 54, 4868, 5593, 253, 14259, 875, 253, 4561, 2505, 285, 247, 3806, 2505, 15, 8801, 7103, 8687, 1907, 1966, 16006, 2281, 253, 3290, 273, 253, 4561, 2505, 1754, 327, 2616, 824, 347, 25253, 13, 2938, 1371, 13, 285, 17200, 15, 733, 310, 8521, 281, 897, 247, 5019, 273, 841, 17082, 323, 247, 11088, 7103, 273, 253, 1566, 434, 3045, 15] \n",
            "\n",
            "Data Example  2 :\n",
            "Question:\n",
            " Can I find information about the code's approach to handling long-running tasks and background jobs?\n",
            "\n",
            "Answer:\n",
            " Yes, the code includes methods for submitting jobs, checking job status, and retrieving job results.\n",
            "It also includes a method for canceling jobs. Additionally, there is a method for sampling multiple\n",
            "outputs from a model, which could be useful for long-running tasks.\n",
            "\n",
            "input_ids:  [5804, 309, 1089, 1491, 670, 253, 2127, 434, 2746, 281, 10885, 1048, 14, 24220, 8892, 285, 4114, 7375, 32, 4374, 13, 253, 2127, 3797, 3082, 323, 29315, 7375, 13, 12669, 2628, 3708, 13, 285, 48484, 2628, 1543, 15, 733, 671, 3797, 247, 1332, 323, 14002, 272, 7375, 15, 9157, 13, 627, 310, 247, 1332, 323, 10491, 2709, 18012, 432, 247, 1566, 13, 534, 812, 320, 4217, 323, 1048, 14, 24220, 8892, 15]\n",
            "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "labels:  [5804, 309, 1089, 1491, 670, 253, 2127, 434, 2746, 281, 10885, 1048, 14, 24220, 8892, 285, 4114, 7375, 32, 4374, 13, 253, 2127, 3797, 3082, 323, 29315, 7375, 13, 12669, 2628, 3708, 13, 285, 48484, 2628, 1543, 15, 733, 671, 3797, 247, 1332, 323, 14002, 272, 7375, 15, 9157, 13, 627, 310, 247, 1332, 323, 10491, 2709, 18012, 432, 247, 1566, 13, 534, 812, 320, 4217, 323, 1048, 14, 24220, 8892, 15] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b84160b8",
      "metadata": {
        "id": "b84160b8"
      },
      "source": [
        "## Various ways of formatting your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca6b7e7",
      "metadata": {
        "id": "dca6b7e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d31bc4e0-3f7b-492b-ecb5-4f8974a5a28e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"How can I evaluate the performance and quality of the generated text from Lamini models?There are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "examples = train_dataset\n",
        "text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "#把question和answer连起来\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0fae24",
      "metadata": {
        "id": "5b0fae24"
      },
      "outputs": [],
      "source": [
        "if \"question\" in examples and \"answer\" in examples:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples and \"response\" in examples:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples and \"output\" in examples:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc40e0ab",
      "metadata": {
        "id": "cc40e0ab"
      },
      "outputs": [],
      "source": [
        "prompt_template_qa = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\n",
        "{answer}\"\"\"\n",
        "\n",
        "#三个井号，类似于INST标符，提示哪些是question，哪些是answer，可以更好提示model\n",
        "#在使用chatGPT时候也可以有更好效果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055b5661",
      "metadata": {
        "id": "055b5661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9ffdde12-58bd-4035-de87-c079bde6f516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"### Question:\\nHow can I evaluate the performance and quality of the generated text from Lamini models?\\n\\n### Answer:\\nThere are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "question = examples[\"question\"][0]\n",
        "answer = examples[\"answer\"][0]\n",
        "\n",
        "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
        "text_with_prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b1923b",
      "metadata": {
        "id": "11b1923b"
      },
      "outputs": [],
      "source": [
        "prompt_template_q = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81a6078",
      "metadata": {
        "id": "f81a6078"
      },
      "outputs": [],
      "source": [
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset_text_only = []\n",
        "finetuning_dataset_question_answer = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "\n",
        "  text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)\n",
        "  finetuning_dataset_text_only.append({\"text\": text_with_prompt_template_qa})\n",
        "\n",
        "  text_with_prompt_template_q = prompt_template_q.format(question=question)\n",
        "  finetuning_dataset_question_answer.append({\"question\": text_with_prompt_template_q, \"answer\": answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f517adf4",
      "metadata": {
        "id": "f517adf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14a1dec-df81-4498-e4ea-85670fd053a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '### Question:\\n'\n",
            "         'How can I evaluate the performance and quality of the generated text '\n",
            "         'from Lamini models?\\n'\n",
            "         '\\n'\n",
            "         '### Answer:\\n'\n",
            "         'There are several metrics that can be used to evaluate the '\n",
            "         'performance and quality of generated text from Lamini models, '\n",
            "         'including perplexity, BLEU score, and human evaluation. Perplexity '\n",
            "         'measures how well the model predicts the next word in a sequence, '\n",
            "         'while BLEU score measures the similarity between the generated text '\n",
            "         'and a reference text. Human evaluation involves having human judges '\n",
            "         'rate the quality of the generated text based on factors such as '\n",
            "         'coherence, fluency, and relevance. It is recommended to use a '\n",
            "         'combination of these metrics for a comprehensive evaluation of the '\n",
            "         \"model's performance.\"}\n"
          ]
        }
      ],
      "source": [
        "pprint(finetuning_dataset_text_only[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5febb8c8",
      "metadata": {
        "id": "5febb8c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3024b72-e5c4-49d0-dcde-1242c370d1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'There are several metrics that can be used to evaluate the '\n",
            "           'performance and quality of generated text from Lamini models, '\n",
            "           'including perplexity, BLEU score, and human evaluation. Perplexity '\n",
            "           'measures how well the model predicts the next word in a sequence, '\n",
            "           'while BLEU score measures the similarity between the generated '\n",
            "           'text and a reference text. Human evaluation involves having human '\n",
            "           'judges rate the quality of the generated text based on factors '\n",
            "           'such as coherence, fluency, and relevance. It is recommended to '\n",
            "           'use a combination of these metrics for a comprehensive evaluation '\n",
            "           \"of the model's performance.\",\n",
            " 'question': '### Question:\\n'\n",
            "             'How can I evaluate the performance and quality of the generated '\n",
            "             'text from Lamini models?\\n'\n",
            "             '\\n'\n",
            "             '### Answer:'}\n"
          ]
        }
      ],
      "source": [
        "pprint(finetuning_dataset_question_answer[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e93258d",
      "metadata": {
        "id": "7e93258d"
      },
      "source": [
        "## Common ways of storing your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e91b0a",
      "metadata": {
        "id": "38e91b0a"
      },
      "outputs": [],
      "source": [
        "#保存成JSON，节省空间，就是生成了一个文本\n",
        "with jsonlines.open(f'lamini_docs_processed.jsonl', 'w') as writer:\n",
        "    writer.write_all(finetuning_dataset_question_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517cfc56",
      "metadata": {
        "id": "517cfc56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efb440c-219a-4f0c-b0a4-6cf89a76d1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 140\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "finetuning_dataset_name = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = load_dataset(finetuning_dataset_name)\n",
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501de373",
      "metadata": {
        "id": "501de373"
      },
      "source": [
        "# 03-Instruction-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5729f6ce",
      "metadata": {
        "id": "5729f6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "8c60da800d25414fa334cd8f116ed6dc",
            "b23b1cdb54744f97a122c28f2321046c",
            "64c97179535645f488212364278e09b0",
            "4190f0b261344c06b29a9811eb005503",
            "2ebbf24b5c9f4b5bb2ad4bd58f833263",
            "9c7977cf4d60424283188d597739f47e",
            "b34a9226b1a141c3a770de2b393754ba",
            "e63e6c77c72b4d11b20fc7a4fdba77b4",
            "801b62bd9abb433c97f6cb1be21927c4",
            "bb8708ade6f84746a0a39140612dd0dd",
            "7f4709aebea24fd78fcf19f01595b990"
          ]
        },
        "outputId": "a0141610-027c-487a-8471-cc48447b1b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c60da800d25414fa334cd8f116ed6dc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import itertools\n",
        "import jsonlines\n",
        "\n",
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a712487",
      "metadata": {
        "id": "4a712487"
      },
      "source": [
        "## Load instruction tuned dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a4ed11a",
      "metadata": {
        "id": "1a4ed11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0408b344c6494ccd804923eb5c0beff2",
            "ece6e2af88e04483930676e1da3f73b2",
            "947eede1be964325b74c039c86465ce9",
            "c3995e41379448d69bb8f1cb37f80ce1",
            "e964c7b6544b448baeb2a4b9abda1214",
            "eea9d893d057430ea892ae76144773c0",
            "bcc78af9e5534ca68026a8fc7d2c8f1b",
            "aa343ac279f44886be03ed185be4182c",
            "13198cb24b6c4835870433fe6427887d",
            "e815aa8be62d48aab20431931d76861d",
            "b257836934fc40e993328f84e87952dd"
          ]
        },
        "outputId": "52c364ed-8122-44a6-ebf9-e83dfffb966f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0408b344c6494ccd804923eb5c0beff2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e48415c",
      "metadata": {
        "id": "9e48415c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40eb5f8b-6ed2-4e1a-bbad-17eb7b758b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction-tuned dataset:\n",
            "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
            "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.'}\n",
            "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\nAn atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}\n",
            "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow can we reduce air pollution?\\n\\n### Response:\\nThere are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}\n",
            "{'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe a time when you had to make a difficult decision.\\n\\n### Response:\\nI had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n"
          ]
        }
      ],
      "source": [
        "m = 5\n",
        "print(\"Instruction-tuned dataset:\")\n",
        "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
        "for j in top_m:\n",
        "  print(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f2cf23",
      "metadata": {
        "id": "54f2cf23"
      },
      "source": [
        "## Two prompt templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441aeced",
      "metadata": {
        "id": "441aeced"
      },
      "outputs": [],
      "source": [
        "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "#在finetuning的时候给出很明确的instruction，规则和限制，来更好完成任务；\n",
        "#和之前的template区别主要就是给了instruction，给了更明确的东西\n",
        "\n",
        "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Response:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a977e7",
      "metadata": {
        "id": "26a977e7"
      },
      "source": [
        "## Hydrate prompts (add data to prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70506882",
      "metadata": {
        "id": "70506882"
      },
      "outputs": [],
      "source": [
        "processed_data = []\n",
        "for j in top_m:\n",
        "  if not j[\"input\"]:\n",
        "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
        "  else:\n",
        "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
        "\n",
        "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f176a0b",
      "metadata": {
        "id": "3f176a0b"
      },
      "outputs": [],
      "source": [
        "pprint(processed_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad87987",
      "metadata": {
        "id": "6ad87987"
      },
      "source": [
        "## Save data to jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8186af6",
      "metadata": {
        "id": "d8186af6"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n",
        "    writer.write_all(processed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277b4ad5",
      "metadata": {
        "id": "277b4ad5"
      },
      "source": [
        "## Try smaller models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37ef86e",
      "metadata": {
        "id": "c37ef86e"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe5ede0",
      "metadata": {
        "id": "afe5ede0"
      },
      "outputs": [],
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize 定义怎么生成token\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f5e568",
      "metadata": {
        "id": "22f5e568"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = load_dataset(finetuning_dataset_path)\n",
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77abca6",
      "metadata": {
        "id": "b77abca6"
      },
      "outputs": [],
      "source": [
        "test_sample = finetuning_dataset[\"test\"][0]\n",
        "print(test_sample)\n",
        "\n",
        "print(inference(test_sample[\"question\"], model, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfe428d",
      "metadata": {
        "id": "8bfe428d"
      },
      "source": [
        "## Compare to finetuned small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3df65ed",
      "metadata": {
        "id": "e3df65ed"
      },
      "outputs": [],
      "source": [
        "instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4c39c3",
      "metadata": {
        "id": "9e4c39c3"
      },
      "outputs": [],
      "source": [
        "print(inference(test_sample[\"question\"], instruction_model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da151c2",
      "metadata": {
        "id": "3da151c2"
      },
      "outputs": [],
      "source": [
        "# Pssst! If you were curious how to upload your own dataset to Huggingface\n",
        "# Here is how we did it\n",
        "\n",
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login\n",
        "\n",
        "# import pandas as pd\n",
        "# import datasets\n",
        "# from datasets import Dataset\n",
        "\n",
        "# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))\n",
        "# finetuning_dataset.push_to_hub(dataset_path_hf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c55279f",
      "metadata": {
        "id": "1c55279f"
      },
      "source": [
        "# 04-Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc9f672",
      "metadata": {
        "id": "bfc9f672"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "\n",
        "from pprint import pprint\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed223760",
      "metadata": {
        "id": "ed223760"
      },
      "source": [
        "## Tokenizing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f247cd15",
      "metadata": {
        "id": "f247cd15"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f55e08",
      "metadata": {
        "id": "37f55e08"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, how are you?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f143c0f3",
      "metadata": {
        "id": "f143c0f3"
      },
      "outputs": [],
      "source": [
        "encoded_text = tokenizer(text)[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec714c33",
      "metadata": {
        "id": "ec714c33"
      },
      "outputs": [],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f31a63",
      "metadata": {
        "id": "50f31a63"
      },
      "outputs": [],
      "source": [
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(\"Decoded tokens back into text: \", decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa452dec",
      "metadata": {
        "id": "aa452dec"
      },
      "source": [
        "## Tokenize multiple texts at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04882f2a",
      "metadata": {
        "id": "04882f2a"
      },
      "outputs": [],
      "source": [
        "list_texts = [\"Hi, how are you?\", \"I'm good\", \"Yes\"]\n",
        "encoded_texts = tokenizer(list_texts)\n",
        "print(\"Encoded several texts: \", encoded_texts[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2e59a4",
      "metadata": {
        "id": "bf2e59a4"
      },
      "source": [
        "## Padding and truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fdbb16",
      "metadata": {
        "id": "09fdbb16"
      },
      "outputs": [],
      "source": [
        "#把不同长度字符拼在一起，padding填没意义的字符，让字符对其，这样才能并行计算\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "encoded_texts_longest = tokenizer(list_texts, padding=True)\n",
        "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c210247b",
      "metadata": {
        "id": "c210247b"
      },
      "outputs": [],
      "source": [
        "encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using truncation: \", encoded_texts_truncation[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41eaf7ba",
      "metadata": {
        "id": "41eaf7ba"
      },
      "outputs": [],
      "source": [
        "tokenizer.truncation_side = \"left\"\n",
        "encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using left-side truncation: \", encoded_texts_truncation_left[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c5d71e",
      "metadata": {
        "id": "80c5d71e"
      },
      "outputs": [],
      "source": [
        "encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)\n",
        "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d09d35",
      "metadata": {
        "id": "00d09d35"
      },
      "source": [
        "## Prepare instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b18547",
      "metadata": {
        "id": "42b18547"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = 'lamini/lamini_docs'\n",
        "dataset = load_dataset(filename)\n",
        "examples = dataset['train']\n",
        "\n",
        "if \"question\" in examples and \"answer\" in examples:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples and \"response\" in examples:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples and \"output\" in examples:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "\n",
        "#进行一些数据拼接工作\n",
        "prompt_template = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\"\n",
        "\n",
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "  text_with_prompt_template = prompt_template.format(question=question)\n",
        "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
        "\n",
        "from pprint import pprint\n",
        "print(\"One datapoint in the finetuning dataset:\")\n",
        "pprint(finetuning_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab0789b",
      "metadata": {
        "id": "6ab0789b"
      },
      "source": [
        "## Tokenize a single example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c320ab",
      "metadata": {
        "id": "b4c320ab"
      },
      "outputs": [],
      "source": [
        "text = finetuning_dataset[0][\"question\"] + finetuning_dataset[0][\"answer\"]\n",
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    padding=True\n",
        ")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1674bc66",
      "metadata": {
        "id": "1674bc66"
      },
      "outputs": [],
      "source": [
        "max_length = 2048\n",
        "max_length = min(\n",
        "    tokenized_inputs[\"input_ids\"].shape[1],\n",
        "    max_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1db47b",
      "metadata": {
        "id": "4c1db47b"
      },
      "outputs": [],
      "source": [
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    truncation=True,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fdaaa14",
      "metadata": {
        "id": "0fdaaa14"
      },
      "outputs": [],
      "source": [
        "tokenized_inputs[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad4c8c54",
      "metadata": {
        "id": "ad4c8c54"
      },
      "source": [
        "## Tokenize the instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8d596b",
      "metadata": {
        "id": "9b8d596b"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    if \"question\" in examples and \"answer\" in examples:\n",
        "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "    elif \"input\" in examples and \"output\" in examples:\n",
        "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "    else:\n",
        "      text = examples[\"output\"][0]\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    max_length = min(\n",
        "        tokenized_inputs[\"input_ids\"].shape[1],\n",
        "        2048\n",
        "    )\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef040ff",
      "metadata": {
        "id": "4ef040ff"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset_loaded = datasets.load_dataset(filename, split=\"train\")\n",
        "\n",
        "tokenized_dataset = finetuning_dataset_loaded.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    drop_last_batch=True\n",
        ")\n",
        "\n",
        "print(tokenized_dataset)\n",
        "pprint(tokenized_dataset[0])\n",
        "\n",
        "#把文本编程数字的形式"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4918320f",
      "metadata": {
        "id": "4918320f"
      },
      "source": [
        "## Prepare test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa77e06e",
      "metadata": {
        "id": "aa77e06e"
      },
      "outputs": [],
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "print(split_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73ea8f8",
      "metadata": {
        "id": "c73ea8f8"
      },
      "source": [
        "### Some datasets for you to try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c9fea2",
      "metadata": {
        "id": "a3c9fea2"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = datasets.load_dataset(finetuning_dataset_path)\n",
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5cb28e",
      "metadata": {
        "id": "cc5cb28e"
      },
      "outputs": [],
      "source": [
        "taylor_swift_dataset = \"lamini/taylor_swift\"\n",
        "bts_dataset = \"lamini/bts\"\n",
        "open_llms = \"lamini/open_llms\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f28cef5d",
      "metadata": {
        "id": "f28cef5d"
      },
      "outputs": [],
      "source": [
        "dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)\n",
        "print(dataset_swiftie[\"train\"][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26f7c645",
      "metadata": {
        "id": "26f7c645"
      },
      "source": [
        "# 05-Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdf34b7",
      "metadata": {
        "id": "3fdf34b7"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "# import config\n",
        "import os\n",
        "import yaml\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "\n",
        "# from utilities import *\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84afec4f",
      "metadata": {
        "id": "84afec4f"
      },
      "source": [
        "## Load the Lamini docs dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50c1f96",
      "metadata": {
        "id": "a50c1f96"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"lamini/lamini_docs\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66bdd766",
      "metadata": {
        "id": "66bdd766"
      },
      "source": [
        "## Set up the model, training config, and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5204b4",
      "metadata": {
        "id": "1d5204b4"
      },
      "outputs": [],
      "source": [
        "model_name = \"EleutherAI/pythia-70m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81716952",
      "metadata": {
        "id": "81716952"
      },
      "outputs": [],
      "source": [
        "# training_config = {\n",
        "#     \"model\": {\n",
        "#         \"pretrained_name\": model_name,\n",
        "#         \"max_length\" : 2048\n",
        "#     },\n",
        "#     \"datasets\": {\n",
        "#         \"use_hf\": use_hf,\n",
        "#         \"path\": dataset_path\n",
        "#     },\n",
        "#     \"verbose\": True\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b113545",
      "metadata": {
        "id": "6b113545"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "dataset = load_dataset(dataset_path)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "# train_dataset = train_dataset.map(\n",
        "#     tokenize_function,\n",
        "#     batched=True,\n",
        "#     batch_size=1,\n",
        "#     drop_last_batch=True\n",
        "# )\n",
        "# test_dataset = test_dataset.map(\n",
        "#     tokenize_function,\n",
        "#     batched=True,\n",
        "#     batch_size=1,\n",
        "#     drop_last_batch=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20661c62",
      "metadata": {
        "id": "20661c62"
      },
      "source": [
        "## Load the base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad86481",
      "metadata": {
        "id": "1ad86481"
      },
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f470887",
      "metadata": {
        "id": "3f470887"
      },
      "outputs": [],
      "source": [
        "device_count = torch.cuda.device_count()\n",
        "if device_count > 0:\n",
        "    logger.debug(\"Select GPU device\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    logger.debug(\"Select CPU device\")\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afcccc87",
      "metadata": {
        "id": "afcccc87"
      },
      "outputs": [],
      "source": [
        "base_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bebeec",
      "metadata": {
        "id": "e6bebeec"
      },
      "source": [
        "## Define function to carry out inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d461b8",
      "metadata": {
        "id": "46d461b8"
      },
      "outputs": [],
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a7pJkRFxuqFJ"
      },
      "id": "a7pJkRFxuqFJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4c312738",
      "metadata": {
        "id": "4c312738"
      },
      "source": [
        "## Try the base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9f4307",
      "metadata": {
        "id": "5c9f4307"
      },
      "outputs": [],
      "source": [
        "test_text = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_text)\n",
        "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
        "print(\"Model's answer: \")\n",
        "print(inference(test_text, base_model, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32bc6275",
      "metadata": {
        "id": "32bc6275"
      },
      "source": [
        "### Setup training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecaf5f7e",
      "metadata": {
        "id": "ecaf5f7e"
      },
      "outputs": [],
      "source": [
        "max_steps = 240"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402887be",
      "metadata": {
        "id": "402887be"
      },
      "outputs": [],
      "source": [
        "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
        "output_dir = trained_model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ef1ff0",
      "metadata": {
        "id": "02ef1ff0"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "\n",
        "  # Learning rate\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs=1,\n",
        "\n",
        "  # Max steps to train for (each step is a batch of data)\n",
        "  # Overrides num_train_epochs, if not -1\n",
        "  max_steps=max_steps,\n",
        "\n",
        "  # Batch size for training\n",
        "  per_device_train_batch_size=1,\n",
        "\n",
        "  # Directory to save model checkpoints\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # Other arguments\n",
        "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
        "  disable_tqdm=False, # Disable progress bars\n",
        "  eval_steps=10, # Number of update steps between two evaluations\n",
        "  save_steps=120, # After # steps model is saved\n",
        "  warmup_steps=0, # Number of warmup steps for learning rate scheduler\n",
        "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
        "  evaluation_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=1,\n",
        "  optim=\"adafactor\",\n",
        "  gradient_accumulation_steps = 4,\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # Parameters for early stopping\n",
        "  load_best_model_at_end=True,\n",
        "  save_total_limit=1,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9d96f4",
      "metadata": {
        "id": "ea9d96f4"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1de4bd9",
      "metadata": {
        "id": "f1de4bd9"
      },
      "source": [
        "### Train a few steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab6f5ff",
      "metadata": {
        "id": "6ab6f5ff"
      },
      "outputs": [],
      "source": [
        "training_output = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a85b793e",
      "metadata": {
        "id": "a85b793e"
      },
      "source": [
        "### Save model locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a79b1b",
      "metadata": {
        "id": "27a79b1b"
      },
      "outputs": [],
      "source": [
        "save_dir = f'{output_dir}/final'\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "print(\"Saved model to:\", save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915cefdd",
      "metadata": {
        "id": "915cefdd"
      },
      "outputs": [],
      "source": [
        "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3de1166",
      "metadata": {
        "id": "c3de1166"
      },
      "outputs": [],
      "source": [
        "finetuned_slightly_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77850200",
      "metadata": {
        "id": "77850200"
      },
      "source": [
        "### Run slightly trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83821430",
      "metadata": {
        "id": "83821430"
      },
      "outputs": [],
      "source": [
        "test_question = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_question)\n",
        "\n",
        "print(\"Finetuned slightly model's answer: \")\n",
        "print(inference(test_question, finetuned_slightly_model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1569683a",
      "metadata": {
        "id": "1569683a"
      },
      "outputs": [],
      "source": [
        "test_answer = test_dataset[0]['answer']\n",
        "print(\"Target answer output (test):\", test_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1d52885",
      "metadata": {
        "id": "c1d52885"
      },
      "source": [
        "### Run same model trained for two epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ef0552",
      "metadata": {
        "id": "b5ef0552"
      },
      "outputs": [],
      "source": [
        "finetuned_longer_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
        "\n",
        "finetuned_longer_model.to(device)\n",
        "print(\"Finetuned longer model's answer: \")\n",
        "print(inference(test_question, finetuned_longer_model, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96bb3285",
      "metadata": {
        "id": "96bb3285"
      },
      "source": [
        "### Run much larger trained model and explore moderation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a33d49",
      "metadata": {
        "id": "e8a33d49"
      },
      "source": [
        "# Explore moderation using small model\n",
        "### First, try the non-finetuned base model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3bebef",
      "metadata": {
        "id": "dd3bebef"
      },
      "outputs": [],
      "source": [
        "base_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "print(inference(\"What do you think of Mars?\", base_model, base_tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b62ad60",
      "metadata": {
        "id": "4b62ad60"
      },
      "source": [
        "### Now try moderation with finetuned small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1d74b1",
      "metadata": {
        "id": "1e1d74b1"
      },
      "outputs": [],
      "source": [
        "print(inference(\"What do you think of Mars?\", finetuned_longer_model, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa404373",
      "metadata": {
        "id": "fa404373"
      },
      "source": [
        "# 06-Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782fa1ff",
      "metadata": {
        "id": "782fa1ff"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import os\n",
        "import yaml\n",
        "import logging\n",
        "import difflib\n",
        "import pandas as pd\n",
        "\n",
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8151522c",
      "metadata": {
        "id": "8151522c"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.load_dataset(\"lamini/lamini_docs\")\n",
        "\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3fb9e2",
      "metadata": {
        "id": "8b3fb9e2"
      },
      "outputs": [],
      "source": [
        "print(test_dataset[0][\"question\"])\n",
        "print(test_dataset[0][\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9ef08d",
      "metadata": {
        "id": "8e9ef08d"
      },
      "outputs": [],
      "source": [
        "model_name = \"lamini/lamini_docs_finetuned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0101f82b",
      "metadata": {
        "id": "0101f82b"
      },
      "source": [
        "## Setup a really basic evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3a592a",
      "metadata": {
        "id": "5f3a592a"
      },
      "outputs": [],
      "source": [
        "def is_exact_match(a, b):\n",
        "    return a.strip() == b.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04747b8",
      "metadata": {
        "id": "c04747b8"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb95acbb",
      "metadata": {
        "id": "fb95acbb"
      },
      "outputs": [],
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  input_ids = tokenizer.encode(\n",
        "      text,\n",
        "      return_tensors=\"pt\",\n",
        "      truncation=True,\n",
        "      max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a06fb78b",
      "metadata": {
        "id": "a06fb78b"
      },
      "source": [
        "## Run model and compare to expected answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a5a213",
      "metadata": {
        "id": "53a5a213"
      },
      "outputs": [],
      "source": [
        "test_question = test_dataset[0][\"question\"]\n",
        "generated_answer = inference(test_question, model, tokenizer)\n",
        "print(test_question)\n",
        "print(generated_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5aba95",
      "metadata": {
        "id": "8c5aba95"
      },
      "outputs": [],
      "source": [
        "answer = test_dataset[0][\"answer\"]\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f4366b",
      "metadata": {
        "id": "71f4366b"
      },
      "outputs": [],
      "source": [
        "exact_match = is_exact_match(generated_answer, answer)\n",
        "print(exact_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a623146",
      "metadata": {
        "id": "7a623146"
      },
      "source": [
        "## Run over entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4b91ed",
      "metadata": {
        "id": "4e4b91ed"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "metrics = {'exact_matches': []}\n",
        "predictions = []\n",
        "for i, item in tqdm(enumerate(test_dataset)):\n",
        "    print(\"i Evaluating: \" + str(item))\n",
        "    question = item['question']\n",
        "    answer = item['answer']\n",
        "\n",
        "    try:\n",
        "      predicted_answer = inference(question, model, tokenizer)\n",
        "    except:\n",
        "      continue\n",
        "    predictions.append([predicted_answer, answer])\n",
        "\n",
        "    #fixed: exact_match = is_exact_match(generated_answer, answer)\n",
        "    exact_match = is_exact_match(predicted_answer, answer)\n",
        "    metrics['exact_matches'].append(exact_match)\n",
        "\n",
        "    if i > n and n != -1:\n",
        "      break\n",
        "print('Number of exact matches: ', sum(metrics['exact_matches']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7fa23f5",
      "metadata": {
        "id": "a7fa23f5"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(predictions, columns=[\"predicted_answer\", \"target_answer\"])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0141bd04",
      "metadata": {
        "id": "0141bd04"
      },
      "source": [
        "## Evaluate all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd0ac19",
      "metadata": {
        "id": "2cd0ac19"
      },
      "outputs": [],
      "source": [
        "evaluation_dataset_path = \"lamini/lamini_docs_evaluation\"\n",
        "evaluation_dataset = datasets.load_dataset(evaluation_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fb53d1",
      "metadata": {
        "id": "a2fb53d1"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(evaluation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07-Deeper into Transformer"
      ],
      "metadata": {
        "id": "fcOnGFldyU7F"
      },
      "id": "fcOnGFldyU7F"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check about the shape of input and output"
      ],
      "metadata": {
        "id": "o_Sp45Tyynrl"
      },
      "id": "o_Sp45Tyynrl"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "text = 'GPT, short for Generative Pre-trained Transformer, represents a groundbreaking advancement in the field of artificial intelligence and natural language processing. Developed by OpenAI, GPT is designed to understand, generate, and interpret human language with remarkable accuracy and fluency. It operates on the principle of machine learning, where the model is initially pre-trained on a vast corpus of text data. This pre-training enables GPT to grasp the intricacies of language, including grammar, context, and even subtleties like humor and sarcasm. Following the pre-training phase, GPT undergoes fine-tuning, where it is further trained on a smaller, more specialized dataset to perform specific tasks like translation, question-answering, and content creation. What sets GPT apart is its deep learning architecture, which consists of multiple layers of transformers—hence the name. These transformers allow the model to process and analyze text in a highly efficient and nuanced manner, making GPT capable of generating text that is often indistinguishable from that written by humans. As technology evolves, GPT continues to push the boundaries of what artificial intelligence can achieve in understanding and mimicking human language.'\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"Characters from the sentence:\", \"\".join(chars))\n",
        "print(\"vocab_size from the sentence: \", vocab_size)\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "train_data = data\n",
        "\n",
        "def get_batch():\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = len(data) - 1 # what is the maximum context length for predictions?\n",
        "# block_size = 192 # what is the maximum context length for predictions?\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "n_embd = 1500\n",
        "n_head = 1\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()   # head_size = 150\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)   # x  ->  embedding size ->  n_head * head_size\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):  # head_size = 150 * n_head 10\n",
        "        B,T,C = x.shape  # batch_size, seq_len, embedding_size   (4, 100, 1500)\n",
        "        k = self.key(x)   # (B,T,C)  (4, 100, 1500) * (1500, 150) -> (4, 100, 150)\n",
        "        q = self.query(x) # (B,T,C)  (4, 100, 1500) * (1500, 150) -> (4, 100, 150)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)  （4, 100, 150) * (4, 150, 100) -> (4, 100, 100)\n",
        "             # you are the best\n",
        "        # you  11  21   23  23\n",
        "        # are\n",
        "        # the\n",
        "        # best\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)  (4, 100, 100)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)  (4, 100, 100) * (100, 1500) -> (4, 100, 150)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)  # n_head * head_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)      # [1],[2],[3]  -> [1,2,3]  # (4, 100, 150) * 10 -> (4, 100, 1500) -> batch, seq_length, embedding_size\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),   # 64 -> 256   信息 -> 维度升高\n",
        "            nn.ReLU(),                  # 激活函数      取出强烈的信息\n",
        "            nn.Linear(4 * n_embd, n_embd),   # 信息维度降低\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)  # 提取信息\n",
        "        self.ffwd = FeedFoward(n_embd)  # GPT感知信息\n",
        "        self.ln1 = nn.LayerNorm(n_embd)  # 归一化\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class BabyGPT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)  # 词嵌入  [0,2,5,6] -> [0.1,0.2,0,7,0.1]  n_embed\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)   #                  [0.9,0.3,0.4,0.1]\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])   # transformer blocks * 4\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)   # 词嵌入 -> 线性层(形状变换) -> logits []  \"your name is GPT-3\" -> seq_len * [0.9,0.3,0.4,0.1] -> \"信息 -> 概率\"  -> token的概率 生成某个token的概率   [0.1, 0.1, 0.8, 0.0]\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers m   idx + next_idx = [y], [yo],[you]\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)   batch_size * seq_len * [0.9,0.3,0.4,0.1]\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)   (T,C)  (4, 100, 1500)\n",
        "        x = tok_emb + pos_emb # (B,T,C)  # 词信息 + 位置信息 (4, 100, 1500)\n",
        "        x = self.blocks(x) # (B,T,C)  # 信息提取 (4, 100, 1500) -> 10 * (4, 100, 150) -> (4, 100, 1500)\n",
        "        x = self.ln_f(x) # (B,T,C)  # 归一化\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)  # 词嵌入 -> 线性层(形状变换) -> logits(概率信息) (4, 100, 1500) * (1500, 39) -> (4, 100, 39)\n",
        "         # I am st .. o\n",
        "         # [ ,'a', .... , ]\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)   # 交叉熵损失函数  - 差距  - minimize 差距\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):   # data pre -> train model -> model serving\n",
        "        # idx is (B, T) array of indices in the current context  # \"pre\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond) # [0,3,2,4,5,6]\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C) # [0.1, 0.2, 0.7]  (4, 100, 39) -> (4, 39)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)  # [0.1, 0.44, 0.46]  -> max 2  boss\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)   \"pre\"  -  I am a  -> \"I am a \" + \"boss\" -> \"I am a boss\" -> model -> \"I am a boss\" -> \"I am a boss\" + \"!\" s\n",
        "        return idx"
      ],
      "metadata": {
        "id": "U31R772PyfUS"
      },
      "id": "U31R772PyfUS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with a babyGPT"
      ],
      "metadata": {
        "id": "G_oaLGsty4Bf"
      },
      "id": "G_oaLGsty4Bf"
    },
    {
      "cell_type": "code",
      "source": [
        "m = BabyGPT()"
      ],
      "metadata": {
        "id": "OMQ_yzoey78G"
      },
      "id": "OMQ_yzoey78G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 1\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "m = m.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "# 使用tqdm添加进度条，并在进度条中显示中间loss值\n",
        "pbar = tqdm(range(500))\n",
        "for steps in pbar:\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch()\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 更新进度条的描述以显示当前的loss值\n",
        "    pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "TNAcjKfDy-iR"
      },
      "id": "TNAcjKfDy-iR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = torch.tensor([encode('GPT')], dtype=torch.long)\n",
        "start_id = start_id.to(device)\n",
        "print(decode(m.generate(idx = start_id, max_new_tokens=200)[0].tolist()))"
      ],
      "metadata": {
        "id": "Vqr6cfpFzMZS"
      },
      "id": "Vqr6cfpFzMZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rethink about the attention mechanism"
      ],
      "metadata": {
        "id": "41xSiR86zLut"
      },
      "id": "41xSiR86zLut"
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "\n",
        "\n",
        "# you are the best\n",
        "# 1    2    3   4\n",
        "torch.manual_seed(42)\n",
        "wei = torch.tril(torch.ones(7, 7))\n",
        "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(7,2)).float()\n",
        "c = wei @ b\n",
        "print('wei=')\n",
        "print(wei)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)\n",
        "\n",
        "     # you are the best\n",
        "\n",
        "# you  11  00   00  00\n",
        "# are  14  23   00  00\n",
        "# the\n",
        "# best"
      ],
      "metadata": {
        "id": "MmTXQGKSzq91"
      },
      "id": "MmTXQGKSzq91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self-attention!\n",
        "#import torch.nn as nn\n",
        "#from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 1,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)  # (1, 8, 32)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)  # x -->捕捉可以当作key的信息\n",
        "query = nn.Linear(C, head_size, bias=False) # x -->捕捉可以当作query的信息\n",
        "value = nn.Linear(C, head_size, bias=False) # x -->捕捉可以当作value的信息\n",
        "\n",
        "print(key.weight)\n",
        "print(query)\n",
        "print(value)\n",
        "\n",
        "k = key(x)   # (B, T, 16)  (1, 8, 32) * (32, 16)  (1, 8, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)  attention score   (1, 8, 8)\n",
        "\n",
        "print(wei[0])\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "print(\"masked:\",wei[0])\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(\"masked:\",wei[0])\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "sg81wSQ70t_p"
      },
      "id": "sg81wSQ70t_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "id": "907hYo_l0v-j"
      },
      "id": "907hYo_l0v-j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c60da800d25414fa334cd8f116ed6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b23b1cdb54744f97a122c28f2321046c",
              "IPY_MODEL_64c97179535645f488212364278e09b0",
              "IPY_MODEL_4190f0b261344c06b29a9811eb005503"
            ],
            "layout": "IPY_MODEL_2ebbf24b5c9f4b5bb2ad4bd58f833263"
          }
        },
        "b23b1cdb54744f97a122c28f2321046c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c7977cf4d60424283188d597739f47e",
            "placeholder": "​",
            "style": "IPY_MODEL_b34a9226b1a141c3a770de2b393754ba",
            "value": ""
          }
        },
        "64c97179535645f488212364278e09b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63e6c77c72b4d11b20fc7a4fdba77b4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_801b62bd9abb433c97f6cb1be21927c4",
            "value": 0
          }
        },
        "4190f0b261344c06b29a9811eb005503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8708ade6f84746a0a39140612dd0dd",
            "placeholder": "​",
            "style": "IPY_MODEL_7f4709aebea24fd78fcf19f01595b990",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "2ebbf24b5c9f4b5bb2ad4bd58f833263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7977cf4d60424283188d597739f47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34a9226b1a141c3a770de2b393754ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63e6c77c72b4d11b20fc7a4fdba77b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "801b62bd9abb433c97f6cb1be21927c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb8708ade6f84746a0a39140612dd0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4709aebea24fd78fcf19f01595b990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0408b344c6494ccd804923eb5c0beff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ece6e2af88e04483930676e1da3f73b2",
              "IPY_MODEL_947eede1be964325b74c039c86465ce9",
              "IPY_MODEL_c3995e41379448d69bb8f1cb37f80ce1"
            ],
            "layout": "IPY_MODEL_e964c7b6544b448baeb2a4b9abda1214"
          }
        },
        "ece6e2af88e04483930676e1da3f73b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea9d893d057430ea892ae76144773c0",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc78af9e5534ca68026a8fc7d2c8f1b",
            "value": "README.md: 100%"
          }
        },
        "947eede1be964325b74c039c86465ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa343ac279f44886be03ed185be4182c",
            "max": 7472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13198cb24b6c4835870433fe6427887d",
            "value": 7472
          }
        },
        "c3995e41379448d69bb8f1cb37f80ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e815aa8be62d48aab20431931d76861d",
            "placeholder": "​",
            "style": "IPY_MODEL_b257836934fc40e993328f84e87952dd",
            "value": " 7.47k/7.47k [00:00&lt;00:00, 478kB/s]"
          }
        },
        "e964c7b6544b448baeb2a4b9abda1214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea9d893d057430ea892ae76144773c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc78af9e5534ca68026a8fc7d2c8f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa343ac279f44886be03ed185be4182c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13198cb24b6c4835870433fe6427887d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e815aa8be62d48aab20431931d76861d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b257836934fc40e993328f84e87952dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbd7db245fc4fe896e8a81cd9638c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_998492119061482697d20f3aeff317f3",
              "IPY_MODEL_c32aae2521a94a658ccfd163de0a5391",
              "IPY_MODEL_756f52f7bb03416caff90f65393d37c5"
            ],
            "layout": "IPY_MODEL_4cb1e5938729476d9c6a12028f25a0e0"
          }
        },
        "998492119061482697d20f3aeff317f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456f291b801d411d8d7db229bed08df3",
            "placeholder": "​",
            "style": "IPY_MODEL_9128703570074f46a692fc0d834c8040",
            "value": "README.md: "
          }
        },
        "c32aae2521a94a658ccfd163de0a5391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c0f5075e144485da51a48455d3688ce",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_072eb8782c654a78a50e4ab0f8cda068",
            "value": 1
          }
        },
        "756f52f7bb03416caff90f65393d37c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f66cdcfa731b425c8a024b153c1e7de4",
            "placeholder": "​",
            "style": "IPY_MODEL_1433e99ad46f420ca32d3d8d47cc10fe",
            "value": " 41.1k/? [00:00&lt;00:00, 909kB/s]"
          }
        },
        "4cb1e5938729476d9c6a12028f25a0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456f291b801d411d8d7db229bed08df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9128703570074f46a692fc0d834c8040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c0f5075e144485da51a48455d3688ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "072eb8782c654a78a50e4ab0f8cda068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f66cdcfa731b425c8a024b153c1e7de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1433e99ad46f420ca32d3d8d47cc10fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df6557d18a8b46708ecb221691022ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67664747bdf44590b8f3041f3932ffa2",
              "IPY_MODEL_e4015752550844a9a8ab57489edc2c1c",
              "IPY_MODEL_e147af5adabc4641938d173ffc3d3762"
            ],
            "layout": "IPY_MODEL_861a25ee5b82446ca2badb8fbce6f132"
          }
        },
        "67664747bdf44590b8f3041f3932ffa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f807060b9ad546f187eeaf1e0d27f6b2",
            "placeholder": "​",
            "style": "IPY_MODEL_5e859a59eb3a4b1c9583ca70653b64e7",
            "value": "Resolving data files: 100%"
          }
        },
        "e4015752550844a9a8ab57489edc2c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e86a9d76e3b49df8daf27a96785a15b",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58f293ea2cff4d16a7965bd74b4a85dc",
            "value": 1024
          }
        },
        "e147af5adabc4641938d173ffc3d3762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211ce442a7bf4b59978ba2602654f706",
            "placeholder": "​",
            "style": "IPY_MODEL_396f222d13bf4109ba139ec76b5c5b86",
            "value": " 1024/1024 [00:04&lt;00:00,  1.74s/it]"
          }
        },
        "861a25ee5b82446ca2badb8fbce6f132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f807060b9ad546f187eeaf1e0d27f6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e859a59eb3a4b1c9583ca70653b64e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e86a9d76e3b49df8daf27a96785a15b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f293ea2cff4d16a7965bd74b4a85dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "211ce442a7bf4b59978ba2602654f706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396f222d13bf4109ba139ec76b5c5b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a53c7c57bd540f78332ad87ac57b03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0600c7e4a2944fd968b0672e9c48263",
              "IPY_MODEL_0a5a82233e434c7c97569edd70028764",
              "IPY_MODEL_af2fc0d2ec284b10a3aae81d5807156f"
            ],
            "layout": "IPY_MODEL_3e9998d92e8148a284b386d73637cc20"
          }
        },
        "e0600c7e4a2944fd968b0672e9c48263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a3062071e94572954c7251087a53d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3cbcaa16023445c69323a349fd9dcacf",
            "value": "Resolving data files: 100%"
          }
        },
        "0a5a82233e434c7c97569edd70028764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf610d964e634377b39807437ae1b1de",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9430dea62a284130a415ceba2f5c6456",
            "value": 1024
          }
        },
        "af2fc0d2ec284b10a3aae81d5807156f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8095cfb4b1564016a18fe2329fccf039",
            "placeholder": "​",
            "style": "IPY_MODEL_b3180a63ccc14c419a3bff8320581b7b",
            "value": " 1024/1024 [00:00&lt;00:00, 37387.86it/s]"
          }
        },
        "3e9998d92e8148a284b386d73637cc20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a3062071e94572954c7251087a53d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbcaa16023445c69323a349fd9dcacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf610d964e634377b39807437ae1b1de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9430dea62a284130a415ceba2f5c6456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8095cfb4b1564016a18fe2329fccf039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3180a63ccc14c419a3bff8320581b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e543fabe46e47afb736ae2522b98f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829adf5eabf2414abd501e37e79f57cd",
              "IPY_MODEL_b4154afba8574bf0848f8f2861e765df",
              "IPY_MODEL_e523f1712e9b48d7aaa37d2f211da0f8"
            ],
            "layout": "IPY_MODEL_8dd1109ac4314494aace28a5d404b2cb"
          }
        },
        "829adf5eabf2414abd501e37e79f57cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b99abed6494eeca700a42085fd5ee3",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b7bbf84b8540e4bb883d0021bc2201",
            "value": "README.md: 100%"
          }
        },
        "b4154afba8574bf0848f8f2861e765df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6053b3613af41dcb09026e831a95fab",
            "max": 577,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8d3dff0dd764402b41adc0b5426f065",
            "value": 577
          }
        },
        "e523f1712e9b48d7aaa37d2f211da0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20855815f6944934848f7e58ac666c05",
            "placeholder": "​",
            "style": "IPY_MODEL_015176cffc8f400e89efff21f6c80336",
            "value": " 577/577 [00:00&lt;00:00, 12.5kB/s]"
          }
        },
        "8dd1109ac4314494aace28a5d404b2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b99abed6494eeca700a42085fd5ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b7bbf84b8540e4bb883d0021bc2201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6053b3613af41dcb09026e831a95fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d3dff0dd764402b41adc0b5426f065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20855815f6944934848f7e58ac666c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015176cffc8f400e89efff21f6c80336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd5070bc8fe4afea59ee2f1b9db2d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c1472b024d74d4195180ca2cf59bb16",
              "IPY_MODEL_c33f0a252b134d88baffbf20ef92c83a",
              "IPY_MODEL_d881cec28d3447159e4afb0cf01cb714"
            ],
            "layout": "IPY_MODEL_4e771e4f69b14415822184eab453976f"
          }
        },
        "3c1472b024d74d4195180ca2cf59bb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c15d1b123244db8c2db4cf9af24367",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b3073e81614c6791b31f6e5037d444",
            "value": "(…)-00000-of-00001-5cdebbc48da41394.parquet: 100%"
          }
        },
        "c33f0a252b134d88baffbf20ef92c83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d4f838061643709f90e2420a1bf8c3",
            "max": 614936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ef3d0c8da3f4eb7a0b13470d50139d4",
            "value": 614936
          }
        },
        "d881cec28d3447159e4afb0cf01cb714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34eabcaa4dd4a83855d8c8b9858de2f",
            "placeholder": "​",
            "style": "IPY_MODEL_10bc9cc7253d4f5ea863fad6c7cc6689",
            "value": " 615k/615k [00:00&lt;00:00, 17.0MB/s]"
          }
        },
        "4e771e4f69b14415822184eab453976f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c15d1b123244db8c2db4cf9af24367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b3073e81614c6791b31f6e5037d444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d4f838061643709f90e2420a1bf8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef3d0c8da3f4eb7a0b13470d50139d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d34eabcaa4dd4a83855d8c8b9858de2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10bc9cc7253d4f5ea863fad6c7cc6689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee8665a6d5f432fbf7885e29094c5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaa740601bcb4613a53aedb4f09252e0",
              "IPY_MODEL_ba7aa6770263421090379af215ec7809",
              "IPY_MODEL_d7f0c7df37134e70908f9f94eef979e9"
            ],
            "layout": "IPY_MODEL_3b458cf64943456c9c79b7a311cb4942"
          }
        },
        "aaa740601bcb4613a53aedb4f09252e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c309d4686e8439fa38277d2d71901f2",
            "placeholder": "​",
            "style": "IPY_MODEL_7fb5d1c03ba042f79194994693a0e1bc",
            "value": "(…)-00000-of-00001-4c77a066a883f339.parquet: 100%"
          }
        },
        "ba7aa6770263421090379af215ec7809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0790fb3ca918464196dc223bbd394764",
            "max": 83671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ce2bc648b714809978ccebe5c89f364",
            "value": 83671
          }
        },
        "d7f0c7df37134e70908f9f94eef979e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff130575dbc14975b1b2601c24982e77",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5d39bf0e214cceb2791dcf1510a32c",
            "value": " 83.7k/83.7k [00:00&lt;00:00, 6.95MB/s]"
          }
        },
        "3b458cf64943456c9c79b7a311cb4942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c309d4686e8439fa38277d2d71901f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb5d1c03ba042f79194994693a0e1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0790fb3ca918464196dc223bbd394764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce2bc648b714809978ccebe5c89f364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff130575dbc14975b1b2601c24982e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5d39bf0e214cceb2791dcf1510a32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9164d035374f8c8a8c9e32f3aba3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08b094cb59df4458a53e88630e721430",
              "IPY_MODEL_d1eaa8b7c5984576b7569f7602d868f8",
              "IPY_MODEL_0911a79504bc4c7ca055c3c31948e1d7"
            ],
            "layout": "IPY_MODEL_ea5621833c8b4c0da8b2a452dc8d1aeb"
          }
        },
        "08b094cb59df4458a53e88630e721430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5111ea32fb494bd0ba5749aeab563017",
            "placeholder": "​",
            "style": "IPY_MODEL_0d0596b354824541ba5c56dd9ef5dc95",
            "value": "Generating train split: 100%"
          }
        },
        "d1eaa8b7c5984576b7569f7602d868f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1bebd9f14943bab744a0038d7a4e93",
            "max": 1260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04634dbb4d104b449326211f5a5b3986",
            "value": 1260
          }
        },
        "0911a79504bc4c7ca055c3c31948e1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b085e0a4f0b04c23a2d2d56f0742aa2c",
            "placeholder": "​",
            "style": "IPY_MODEL_cd468c5960e5401e8acabbe2a06fcd38",
            "value": " 1260/1260 [00:00&lt;00:00, 19424.21 examples/s]"
          }
        },
        "ea5621833c8b4c0da8b2a452dc8d1aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5111ea32fb494bd0ba5749aeab563017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0596b354824541ba5c56dd9ef5dc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1bebd9f14943bab744a0038d7a4e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04634dbb4d104b449326211f5a5b3986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b085e0a4f0b04c23a2d2d56f0742aa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd468c5960e5401e8acabbe2a06fcd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e99d68b6034c46a6dcf20066a3adde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b359f3de18634cc5ac99a4188ce6e2c3",
              "IPY_MODEL_11267b13b17c4243b40b376c163a38f7",
              "IPY_MODEL_b0946875479a463ea3a9848a0fff2f9e"
            ],
            "layout": "IPY_MODEL_542246a5d523423cb9f51f099649a8b6"
          }
        },
        "b359f3de18634cc5ac99a4188ce6e2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab0b2f5e2b84fc597e34ec7d3351448",
            "placeholder": "​",
            "style": "IPY_MODEL_7721ba052c14443aa5b98e31b106018a",
            "value": "Generating test split: 100%"
          }
        },
        "11267b13b17c4243b40b376c163a38f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2333b9e7baa4f27aa770f129a4397ce",
            "max": 140,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cfbfe8f75544c0ba3afab3dab67d37c",
            "value": 140
          }
        },
        "b0946875479a463ea3a9848a0fff2f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc299360736440dadd3644d98085a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_beb058663ed64b488188480b442a36d9",
            "value": " 140/140 [00:00&lt;00:00, 5666.06 examples/s]"
          }
        },
        "542246a5d523423cb9f51f099649a8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab0b2f5e2b84fc597e34ec7d3351448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7721ba052c14443aa5b98e31b106018a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2333b9e7baa4f27aa770f129a4397ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfbfe8f75544c0ba3afab3dab67d37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffc299360736440dadd3644d98085a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb058663ed64b488188480b442a36d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}